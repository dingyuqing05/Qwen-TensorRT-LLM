# Qwen-TensorRT-LLM

### 总述

Qwen-TensorRT-LLM项目是将阿里云研发的通义千问大模型系列中的[Qwen-7B-Chat](https://huggingface.co/Qwen/Qwen-7B-Chat)移植到TensorRT-LLM下并做性能上的优化，[Qwen-7B](https://github.com/QwenLM/Qwen-7B/blob/main/README.md)是在超大规模的预训练数据上进行训练得到的大语言模型，其模型结构为Transformer架构。Qwen-7B模型的预训练数据类型多样，覆盖广泛，包括大量网络文本、专业书籍、代码等。本项目中移植的[Qwen-7B-Chat](https://huggingface.co/Qwen/Qwen-7B-Chat)则是在Qwen-7B的基础上使用对齐机制打造的基于大语言模型的AI助手。本项目是[NVIDIA TensorRT Hackathon2023](https://github.com/NVIDIA/trt-samples-for-hackathon-cn/blob/master/Hackathon2023/HackathonGuide.md)的复赛项目，选题类型是2+4.



| 仓库主页地址    |   原始模型   |  原始模型代码URL  |  选题类型  |
| :------------- | :---------: | :--------------: | :--------: | 
| [Qwen-TensorRT-LLM](https://github.com/dingyuqing05/QwenTRTLLM)     |  [Qwen-7B-Chat](https://huggingface.co/Qwen/Qwen-7B-Chat)    |   [Qwen-7B-Chat](https://huggingface.co/Qwen/Qwen-7B-Chat/tree/main)     |  2+4  |
